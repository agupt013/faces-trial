# FACES 2.0 (Trial Version)

FACES 2.0 is a face recognition application based on a method of machine learning known as a deep neural network. Funded by the Kress Foundation, it is designed to automatically test the degree of probability of a shared identification between different works of portrait art--that is, non-photographic portraits that are subject to the subjectivity of artistic interpretation. When used correctly with good images, it has the potential to match what is known with a given unknown--something that is unlikely to be accidental--and yields results that may be considered probable. In this, FACES has the potential to provide previously unnoticeable or unconfirmable information by contributing categories of quantifiable data for researchers to factor into their own analyses.

## Usage Information
vggArt.py takes two inputs. One is path to test image and other ispath to reference image.
     Usage: python vggArt.py -t \<path of test image\> -r \<path of reference image\>

## Required files
You MUST download and save these files where you have saved the vggArt.py file. PLEASE DO NOT CHANGE THE NAME OF THE FILES.
[Link] (https://goo.gl/BSzLHb)

## Software Live (in progress) [here](http://faces2.engr.ucr.edu/ "FACES 2.0 Homepage")

## Paper
If you use our work please cite our paper [link](http://vcg.engr.ucr.edu/publications/ICME.pdf 'VCG: ICME 2018'):


@article{guptadeep,
  title={Deep Learning based Identity Verification in Renaissance Portraits},
  author={Gupta, Akash and Mithun, Niluthpol C and Rudolph, Conrad and Roy-Chowdhury, Amit K}
}

## Note:
This code is older version of what is presented in the paper mentioned above. I'm still working on refactoring the code and if approved by the PI I'll upload it here.

## Contact
Email - agupt013@ucr.edu
